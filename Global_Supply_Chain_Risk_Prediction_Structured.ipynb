{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udea2 Global Supply Chain Delay & Disruption Risk Prediction\n",
        "\n",
        "This notebook builds a binary classification model to predict whether a shipment will be **delayed or on-time**.\n",
        "It covers the full ML pipeline: data loading \u2192 EDA \u2192 feature engineering \u2192 model training \u2192 evaluation \u2192 export."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/global_supply_chain_disruption_v1.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploratory Data Analysis\n",
        "\n",
        "Quick inspection of the dataset: shape, types, summary statistics, and column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Shape:', df.shape)\n",
        "print('\\nColumn names:')\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Engineering\n",
        "\n",
        "- Parse `Order_Date` into year, month, day, and day-of-week components.\n",
        "- Drop `Order_ID` (non-informative identifier).\n",
        "- Create binary target `Is_Delayed` (1 if `Delay_Days > 0`, else 0).\n",
        "- Remove **data-leaky columns** that would not be available at prediction time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse date features\n",
        "df['Order_Date'] = pd.to_datetime(df['Order_Date'])\n",
        "df['Order_Year']      = df['Order_Date'].dt.year\n",
        "df['Order_Month']     = df['Order_Date'].dt.month\n",
        "df['Order_Day']       = df['Order_Date'].dt.day\n",
        "df['Order_DayOfweek'] = df['Order_Date'].dt.dayofweek\n",
        "\n",
        "df = df.drop('Order_ID', axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create binary target variable\n",
        "df['Is_Delayed'] = df['Delay_Days'].apply(lambda x: 1 if x > 0 else 0)\n",
        "print('Target distribution (normalised):')\n",
        "print(df['Is_Delayed'].value_counts(normalize=True).round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop leaky columns (known only AFTER delivery)\n",
        "leaky_cols = [\n",
        "    'Delay_Days',\n",
        "    'Actual_Lead_Time_Days',\n",
        "    'Delivery_Status',\n",
        "    'Disruption_Event',\n",
        "    'Mitigation_Action_Taken'\n",
        "]\n",
        "df = df.drop(leaky_cols, axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data Preprocessing\n",
        "\n",
        "- Select safe (non-leaky) features.\n",
        "- Label-encode categorical columns.\n",
        "- Split into train / test sets (80 / 20).\n",
        "- Scale features with `StandardScaler` for distance-based models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "safe_cols = [\n",
        "    'Origin_City', 'Destination_City', 'Route_Type', 'Transportation_Mode',\n",
        "    'Product_Category', 'Base_Lead_Time_Days', 'Scheduled_Lead_Time_Days',\n",
        "    'Geopolitical_Risk_Index', 'Weather_Severity_Index', 'Inflation_Rate_Pct',\n",
        "    'Shipping_Cost_USD', 'Order_Weight_Kg',\n",
        "    'Order_Year', 'Order_Month', 'Order_Day', 'Order_DayOfweek'\n",
        "]\n",
        "\n",
        "x = df[safe_cols].copy()\n",
        "y = df['Is_Delayed'].copy()\n",
        "\n",
        "print('Features:', x.columns.tolist())\n",
        "print('\\nTarget distribution:')\n",
        "print(y.value_counts(normalize=True).round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Label-encode categorical columns\n",
        "le = LabelEncoder()\n",
        "cat_cols = x.select_dtypes(include='object').columns\n",
        "for col in cat_cols:\n",
        "    x[col] = le.fit_transform(x[col])\n",
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train / test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=23)\n",
        "\n",
        "print('Train shape:', x_train.shape)\n",
        "print('Test shape: ', x_test.shape)\n",
        "print('\\nTrain target distribution:')\n",
        "print(y_train.value_counts(normalize=True).round(3))\n",
        "print('\\nTest target distribution:')\n",
        "print(y_test.value_counts(normalize=True).round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features (required for LR, SVM, KNN)\n",
        "sc = StandardScaler()\n",
        "x_train_sc = sc.fit_transform(x_train)\n",
        "x_test_sc  = sc.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Training\n",
        "\n",
        "Five classifiers are trained and compared:\n",
        "1. Logistic Regression\n",
        "2. Random Forest\n",
        "3. XGBoost\n",
        "4. Support Vector Machine (SVM)\n",
        "5. K-Nearest Neighbours (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Logistic Regression\n",
        "lr = LogisticRegression(max_iter=5000, class_weight='balanced')\n",
        "lr.fit(x_train_sc, y_train)\n",
        "y_pred_lr = lr.predict(x_test_sc)\n",
        "y_prob_lr = lr.predict_proba(x_test_sc)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=300, class_weight='balanced', random_state=23)\n",
        "rf.fit(x_train, y_train)\n",
        "y_pred_rf = rf.predict(x_test)\n",
        "y_prob_rf = rf.predict_proba(x_test)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. XGBoost\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    scale_pos_weight=7,\n",
        "    eval_metric='logloss',\n",
        "    random_state=23\n",
        ")\n",
        "xgb.fit(x_train, y_train)\n",
        "y_pred_xgb = xgb.predict(x_test)\n",
        "y_prob_xgb = xgb.predict_proba(x_test)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Support Vector Machine\n",
        "svm = SVC(kernel='rbf', probability=True, class_weight='balanced')\n",
        "svm.fit(x_train_sc, y_train)\n",
        "y_pred_svm = svm.predict(x_test_sc)\n",
        "y_prob_svm = svm.predict_proba(x_test_sc)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. K-Nearest Neighbours\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(x_train_sc, y_train)\n",
        "y_pred_knn = knn.predict(x_test_sc)\n",
        "y_prob_knn = knn.predict_proba(x_test_sc)[:, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Evaluation & Comparison\n",
        "\n",
        "All five models are evaluated on Accuracy and ROC-AUC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\n",
        "    'LR' : (y_pred_lr,  y_prob_lr),\n",
        "    'RF' : (y_pred_rf,  y_prob_rf),\n",
        "    'XGB': (y_pred_xgb, y_prob_xgb),\n",
        "    'SVM': (y_pred_svm, y_prob_svm),\n",
        "    'KNN': (y_pred_knn, y_prob_knn),\n",
        "}\n",
        "\n",
        "for name, (pred, prob) in models.items():\n",
        "    print(f'\\n==== {name} ====')\n",
        "    print('Accuracy:', accuracy_score(y_test, pred))\n",
        "    print('ROC-AUC:', roc_auc_score(y_test, prob))\n",
        "    print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary comparison table\n",
        "model_results = pd.DataFrame({\n",
        "    'Model'   : ['Logistic Regression', 'Random Forest', 'XGBoost', 'SVM', 'KNN'],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred_lr),\n",
        "        accuracy_score(y_test, y_pred_rf),\n",
        "        accuracy_score(y_test, y_pred_xgb),\n",
        "        accuracy_score(y_test, y_pred_svm),\n",
        "        accuracy_score(y_test, y_pred_knn),\n",
        "    ],\n",
        "    'ROC_AUC' : [\n",
        "        roc_auc_score(y_test, y_prob_lr),\n",
        "        roc_auc_score(y_test, y_prob_rf),\n",
        "        roc_auc_score(y_test, y_prob_xgb),\n",
        "        roc_auc_score(y_test, y_prob_svm),\n",
        "        roc_auc_score(y_test, y_prob_knn),\n",
        "    ]\n",
        "}).sort_values(by='ROC_AUC', ascending=False)\n",
        "\n",
        "print(model_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance \u2014 Random Forest\n",
        "feat_imp_rf = pd.Series(rf.feature_importances_, index=x_train.columns).sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "feat_imp_rf.head(15).plot(kind='barh')\n",
        "plt.title('Top 15 Feature Importances (Random Forest)')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Best Model \u2014 XGBoost (Tuned)\n",
        "\n",
        "Re-train XGBoost with tuned hyperparameters, evaluate with a confusion matrix, and inspect feature importances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final XGBoost model\n",
        "xgb_final = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]),\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_final.fit(x_train, y_train)\n",
        "\n",
        "y_pred = xgb_final.predict(x_test)\n",
        "y_prob = xgb_final.predict_proba(x_test)[:, 1]\n",
        "\n",
        "print('=== FINAL XGBOOST MODEL ===')\n",
        "print('Accuracy:', round(accuracy_score(y_test, y_pred), 4))\n",
        "print('ROC-AUC :', round(roc_auc_score(y_test, y_prob), 4))\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['On-Time', 'Delayed'],\n",
        "            yticklabels=['On-Time', 'Delayed'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix \u2014 XGBoost')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importances \u2014 XGBoost\n",
        "feat_imp_xgb = pd.Series(\n",
        "    xgb_final.feature_importances_,\n",
        "    index=x_train.columns\n",
        ").sort_values(ascending=False).head(15)\n",
        "\n",
        "feat_imp_xgb.plot(kind='bar', figsize=(6, 4))\n",
        "plt.title('Top 15 Feature Importances \u2014 XGBoost')\n",
        "plt.ylabel('Importance Score')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Save Model\n",
        "\n",
        "Serialise the trained XGBoost model to disk using `joblib`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(xgb_final, 'xgb_supply_chain_model.pkl')\n",
        "print('Model saved \u2192 xgb_supply_chain_model.pkl')"
      ]
    }
  ]
}